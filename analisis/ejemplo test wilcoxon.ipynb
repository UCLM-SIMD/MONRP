{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "everyday-metallic",
   "metadata": {},
   "source": [
    "**Ejemplo de test de wilcoxon (test de suma de rango), no pareado y no paramétrico**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mighty-tulsa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.69615 4.1091\n",
      "0.01016520189195626\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ranksums\n",
    "import numpy as np\n",
    "\n",
    "#valor de la métrica de interés obtenida en cada una de las 10 ejecuciones del algoritmoA en el dataset X:\n",
    "performance_A=[4.567,7.567,5.678,5.567,8.4545,6.666,7.786,2.345,8.764,9.567]\n",
    "#valor de la métrica de interés obtenida en cada una de las 10 ejecuciones del algoritmoB en el dataset X:\n",
    "performance_B=[2.345,1.445,2.345,5.345,3.456,6.567,4.344,6.456,3.443,5.345]\n",
    "\n",
    "#veo que A tiene mayor media que B\n",
    "print(np.mean(performance_A),np.mean(performance_B))\n",
    "\n",
    "#para rechazar que esta diferencia sea por hazar (unos pocos valores inusualmente altos que aumentan la media), hago un test estadístico.\n",
    "#Como los arrays tienen menos de 30 valores, no puedo suponer que siguen una distribución normal, así que el test tiene que ser no paramétrico\n",
    "#Como el valor de performance_A[i] no se calcula sobre los mismos datos que performance_B[i], el test es no pareado.\n",
    "#--> test de wilcoxon, también conocido como test de suma de rango.\n",
    "#la llamada a ranksums devuelve 2 valores. me interesa el segundo, el p-value. Si p-value<0.05, entonces las medias sí son\n",
    "#estadísticamente diferentes, y por lo tanto el algoritmo A será estadísticamente mejor que B en la métrica comparada.\n",
    "_, p = ranksums(performance_A, performance_B)\n",
    "print(p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-rebecca",
   "metadata": {},
   "source": [
    "**Lo mismo, pero preparado para comparar varias métricas para 2 algoritmos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "practical-departure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métrica</th>\n",
       "      <th>Algoritmo A</th>\n",
       "      <th>Algoritmo B</th>\n",
       "      <th>p-valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Métrica 0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Métrica 1</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.524</td>\n",
       "      <td>0.131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Métrica 2</td>\n",
       "      <td>0.533</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Métrica 3</td>\n",
       "      <td>0.619</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.041*</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Métrica Algoritmo A Algoritmo B p-valor\n",
       "0  Métrica 0       0.399       0.543   0.406\n",
       "1  Métrica 1       0.689       0.524   0.131\n",
       "2  Métrica 2       0.533       0.409   0.326\n",
       "3  Métrica 3       0.619       0.378  0.041*"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "  Métrica & Algoritmo A & Algoritmo B & p-valor \\\\\n",
      "\\midrule\n",
      "Métrica 0 &       0.399 &       0.543 &   0.406 \\\\\n",
      "Métrica 1 &       0.689 &       0.524 &   0.131 \\\\\n",
      "Métrica 2 &       0.533 &       0.409 &   0.326 \\\\\n",
      "Métrica 3 &       0.619 &       0.378 &  0.041* \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import ranksums\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#simulo una matriz de 10 valores para 4 métricas\n",
    "num_metricas=4\n",
    "performances_A=np.random.random_sample((num_metricas,10))\n",
    "performances_B=np.random.random_sample((num_metricas,10))\n",
    "#print(\"Valores Simulados para el Algoritmo A:\\n\", performances_A,\"\\n\")\n",
    "#print(\"Valores Simulados para el Algoritmo B:\\n\", performances_B,\"\\n\")\n",
    "\n",
    "#para ir recogiendo los resultados que quiero mostrar\n",
    "results=list()\n",
    "signif_indices=[]\n",
    "\n",
    "\n",
    "#hago el test para cada métrica, comparando los algoritmos A y B\n",
    "for j in range(num_metricas):\n",
    "    results.append(\"Métrica \"+str(j))\n",
    "    results.append(\"{:.3f}\".format(np.mean((performances_A[j]))))\n",
    "    results.append(\"{:.3f}\".format(np.mean(performances_B[j])))\n",
    "    \n",
    "    _, p = ranksums(performances_A[j], performances_B[j])\n",
    "    if p>=0.05:\n",
    "        mark = ''\n",
    "    else:\n",
    "        mark = '*'\n",
    "        signif_indices.append(j)\n",
    "    p =\"{:.3f}\".format(p)+mark\n",
    "    results.append(p)\n",
    "\n",
    "#formatear la salida\n",
    "table = np.asmatrix(results)\n",
    "table=table.reshape(num_metricas,4)\n",
    "table_df=pd.DataFrame(table,columns=[\"Métrica\",\"Algoritmo A\",\"Algoritmo B\",\"p-valor\"])\n",
    "display(table_df)\n",
    "print(table_df.to_latex(index=False))\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}